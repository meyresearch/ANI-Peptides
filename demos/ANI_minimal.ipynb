{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aad2039",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbowley/miniconda3/envs/ani/lib/python3.9/site-packages/torchani/__init__.py:55: UserWarning: Dependency not satisfied, torchani.ase will not be available\n",
      "  warnings.warn(\"Dependency not satisfied, torchani.ase will not be available\")\n",
      "Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n",
      "/home/mbowley/miniconda3/envs/ani/lib/python3.9/site-packages/torch/functional.py:1069: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1640869844479/work/aten/src/ATen/native/TensorShape.cpp:2156.)\n",
      "  return _VF.cartesian_prod(tensors)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mbowley/miniconda3/envs/ani/lib/python3.9/site-packages/torchani/resources/\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from openmm.app import *\n",
    "from openmm import *\n",
    "from openmm.unit import *\n",
    "from openmmml import MLPotential\n",
    "import sys\n",
    "\n",
    "# Setup\n",
    "pdb = PDBFile(\"aaa.pdb\")\n",
    "pdb.topology.setPeriodicBoxVectors(None)\n",
    "potential = MLPotential('ani2x')\n",
    "system = potential.createSystem(pdb.topology)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04715fa6",
   "metadata": {},
   "source": [
    "# Works fine on CPU (slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10fe30d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W BinaryOps.cpp:595] Warning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "integrator = LangevinIntegrator(\n",
    "    300 * kelvin, \n",
    "    1 / picosecond, \n",
    "    1.0 * femtosecond,\n",
    ")\n",
    "simulation = Simulation(\n",
    "    pdb.topology,\n",
    "    system,\n",
    "    integrator,\n",
    "    Platform.getPlatformByName(\"CPU\"),\n",
    ")\n",
    "simulation.context.setPositions(pdb.positions)\n",
    "simulation.minimizeEnergy()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aea913",
   "metadata": {},
   "source": [
    "# Breaks with CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18de8aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W LegacyTypeDispatch.h:79] Warning: AutoNonVariableTypeMode is deprecated and will be removed in 1.10 release. For kernel implementations please use AutoDispatchBelowADInplaceOrView instead, If you are looking for a user facing API to enable running your inference-only workload, please use c10::InferenceMode. Using AutoDispatchBelowADInplaceOrView in user code is under risk of producing silent wrong result in some edge cases. See Note [AutoDispatchBelowAutograd] for more details. (function operator())\n"
     ]
    }
   ],
   "source": [
    "integrator = LangevinIntegrator(\n",
    "    300 * kelvin, \n",
    "    1 / picosecond, \n",
    "    1.0 * femtosecond,\n",
    ")\n",
    "simulation = Simulation(\n",
    "    pdb.topology,\n",
    "    system,\n",
    "    integrator,\n",
    "    Platform.getPlatformByName(\"CUDA\"),\n",
    ")\n",
    "simulation.context.setPositions(pdb.positions)\n",
    "simulation.minimizeEnergy()\n",
    "simulation.step(100)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a3a8ed",
   "metadata": {},
   "source": [
    "# Troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb7bdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openmm                    7.7.0            py39h792354b_0    conda-forge\n",
      "openmm-torch              0.5             cuda112py39hb628e3f_0    conda-forge\n",
      "openmmml                  1.0                      pypi_0    pypi\n",
      "pytorch                   1.10.0          cuda112py39h3ad47f5_1    conda-forge\n",
      "pytorch-gpu               1.10.0          cuda112py39h0bbbad9_1    conda-forge\n",
      "torchani                  2.2.3.dev2+g3dfbaf4          pypi_0    pypi\n"
     ]
    }
   ],
   "source": [
    "!conda list | grep -E \"torch|openmm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8912a80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "<torch.cuda.device object at 0x7fafd317f0a0>\n",
      "4\n",
      "NVIDIA GeForce GTX 1080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
